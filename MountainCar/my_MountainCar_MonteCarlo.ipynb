{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MountainCar-v0 Question: \n",
    "\n",
    "### Observation\n",
    "观测值，即智能体的状态，包括位置和速度，具体取值范围如下：  \n",
    "位置：-1.2 —— 0.6  \n",
    "速度：-0.07 —— 0.07\n",
    "\n",
    "### Actions\n",
    "\n",
    "智能体的行为，一种只有三种：  \n",
    "0（向左）  \n",
    "1（不动）  \n",
    "2（向右）\n",
    "\n",
    "### Reward\n",
    "\n",
    "每一步的回报为-1，到达目标山峰的回报为0.5。\n",
    "到达左边山顶没有定义，相当于触碰了墙壁。\n",
    "\n",
    "### Starting State\n",
    "\n",
    "位置为(-0.6，-0.4)之间的随机位置，速度为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56164963,  0.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入模型，MountainCar问题\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本参数\n",
    "alpha = 0.5 #学习率\n",
    "gama = 0.95 #折现因子\n",
    "episodes_num = 5000 #训练轮数\n",
    "display_num = 200 #训练时每隔多少轮显示进度\n",
    "Qtable_size = 20 #Q表的长度\n",
    "\n",
    "#离散化参数\n",
    "discrete_size = [Qtable_size] * len(env.observation_space.high) #20*20\n",
    "discrete_step = (env.observation_space.high - env.observation_space.low) / discrete_size #单位步长\n",
    "q_table = np.zeros(discrete_size + [env.action_space.n]) #Q表初始化，大小：20*20*3\n",
    "\n",
    "#ε参数\n",
    "#初始为１，后续随训练轮数逐渐减小\n",
    "epsilon = 1\n",
    "start_episode = 1\n",
    "end_episode = episodes_num//2\n",
    "#每步递减值\n",
    "de_step = epsilon/(end_episode - start_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#辅助函数\n",
    "#离散化状态——将连续的状态变位离散的状态\n",
    "def get_discrete_state (state):\n",
    "    discrete_state = (state - env.observation_space.low) // discrete_step\n",
    "    return tuple(discrete_state.astype(int))\n",
    "\n",
    "#ε—贪心策略执行行动\n",
    "def take_epilon_greedy_action(state, epsilon):\n",
    "    discrete_state = get_discrete_state(state)\n",
    "    if np.random.random() < epsilon:\n",
    "        action = np.random.randint(0,env.action_space.n)\n",
    "    else:\n",
    "        action = np.argmax(q_table[discrete_state])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0\n",
      "episode: 200\n",
      "episode: 400\n",
      "episode: 600\n",
      "episode: 800\n",
      "episode: 1000\n",
      "episode: 1200\n",
      "episode: 1400\n",
      "episode: 1600\n",
      "episode: 1800\n",
      "episode: 2000\n",
      "episode: 2200\n",
      "episode: 2400\n",
      "episode: 2600\n",
      "episode: 2800\n",
      "episode: 3000\n",
      "episode: 3200\n",
      "episode: 3400\n",
      "episode: 3600\n",
      "episode: 3800\n",
      "episode: 4000\n",
      "episode: 4200\n",
      "episode: 4400\n",
      "episode: 4600\n",
      "episode: 4800\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "for episode in range(episodes_num):\n",
    "    # initiate reward every episode\n",
    "    if episode % display_num == 0:\n",
    "        print(\"episode: {}\".format(episode))\n",
    "        render = True\n",
    "    else:\n",
    "        render = False\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    A_list = [] #行为存储\n",
    "    S_list = [] #状态存储\n",
    "    R_list = [] #回报存储\n",
    "    Done_list = [] #完成情况存储\n",
    "    num_T = 0 #序列长度\n",
    "    #生成序列\n",
    "    while not done:\n",
    "        S_list.append(state)\n",
    "        #行为策略：St——At\n",
    "        action = take_epilon_greedy_action(state, epsilon)\n",
    "        A_list.append(action)\n",
    "        #St，At——Rt+1，St+1\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        R_list.append(reward)\n",
    "        Done_list.append(done)\n",
    "        state = next_state\n",
    "        num_T = num_T + 1\n",
    "    Gt = 0\n",
    "    #根据序列更新Q表\n",
    "    for i in range(num_T):\n",
    "        temp_t = num_T - i - 1\n",
    "        if not Done_list[temp_t]:\n",
    "            Gt = gama * Gt + R_list[temp_t] #Gt迭代计算\n",
    "            td_target = Gt\n",
    "            q_table[get_discrete_state(S_list[temp_t])][A_list[temp_t]] += alpha * (td_target - q_table[get_discrete_state(S_list[temp_t])][A_list[temp_t]])\n",
    "        else:\n",
    "            q_table[get_discrete_state(S_list[temp_t])][A_list[temp_t]] = 0\n",
    "\n",
    "    # ε值的递减\n",
    "    if end_episode >= episode >= start_episode:\n",
    "        epsilon -= de_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练结果测试\n",
    "done = False\n",
    "state = env.reset()\n",
    "while not done:\n",
    "    action = np.argmax(q_table[get_discrete_state(state)])\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    state = next_state\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
